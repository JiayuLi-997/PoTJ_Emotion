{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6c2df60",
   "metadata": {},
   "source": [
    "# 合并词典和句典\n",
    "- 增加了2019-12到2020-2的三个月数据 （2019-12需截断到12.27之后）\n",
    "- 使用2020-01-20开始的数据\n",
    "\n",
    "Steps:\n",
    "1. 分别读取词典、句典匹配的快、慢微博\n",
    "2. **删除部分标注不合理的句典pattern**\n",
    "3. 合并词典快和句典快，删除完全相同的（同用户&ID），并统计数目；慢同理\n",
    "4. 在快微博dataset中，删除内容相似度过高的，并统计数目（threshold需要人工决定）；慢同理\n",
    "5. 快与慢都出现的，去重，作为单独的dataset，both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6ab914e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from matplotlib import pyplot as plt\n",
    "import json\n",
    "# from harvesttext import HarvestText\n",
    "from tqdm.notebook import tqdm\n",
    "# from harvesttext.resources import get_qh_typed_words\n",
    "from datetime import datetime, timedelta\n",
    "import sys\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1358c68c",
   "metadata": {},
   "source": [
    "### 1. 分别读取词典、句典匹配的快、慢微博"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5212da53",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_version = \"0911\"\n",
    "for month in os.listdir(\"Words/output/%s/Weibo-COV_V2_fast\"%(new_version)):\n",
    "    slow = pd.read_csv(\"Words/output/%s/Weibo-COV_V2_slow/%s\"%(new_version,month))\n",
    "    fast = pd.read_csv(\"Words/output/%s/Weibo-COV_V2_fast/%s\"%(new_version,month))\n",
    "    words_fast = words_fast.append(fast,ignore_index=True)\n",
    "    words_slow = words_slow.append(slow,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03223076",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_version = \"0911\"\n",
    "for month in os.listdir(\"Words/output/%s/Weibo-COV_V2_fast\"%(new_version)):\n",
    "    slow = pd.read_csv(\"Sentence/output/%s_demo/Weibo-COV_V2_slow/%s\"%(new_version,month))\n",
    "    fast = pd.read_csv(\"Sentence/output/%s_demo/Weibo-COV_V2_fast/%s\"%(new_version,month))\n",
    "    sentence_fast = sentence_fast.append(fast,ignore_index=True)\n",
    "    sentence_slow = sentence_slow.append(slow,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc559bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_slow = sentence_slow.append(sentence_slow_new,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff17db45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "词典（快）：24238, 词典（慢）：1783\n",
      "句典（快）：28158, 句典（慢）：16285\n"
     ]
    }
   ],
   "source": [
    "# 2. 从2019-12-27开始\n",
    "print(\"词典（快）：%d, 词典（慢）：%d\"%(words_fast.shape[0],words_slow.shape[0]))\n",
    "print(\"句典（快）：%d, 句典（慢）：%d\"%(sentence_fast.shape[0],sentence_slow.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ccc11a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "词典（快）：24224, 词典（慢）：1772\n",
      "句典（快）：28157, 句典（慢）：16285\n"
     ]
    }
   ],
   "source": [
    "words_fast = words_fast.loc[words_fast.created_at>='2020-01-20'].reset_index(drop=True).copy()\n",
    "words_slow = words_slow.loc[words_slow.created_at>='2020-01-20'].reset_index(drop=True).copy()\n",
    "sentence_slow = sentence_slow.loc[sentence_slow.created_at>='2020-01-20'].reset_index(drop=True).copy()\n",
    "sentence_fast = sentence_fast.loc[sentence_fast.created_at>='2020-01-20'].reset_index(drop=True).copy()\n",
    "# 3. 从2020-01-20开始\n",
    "print(\"词典（快）：%d, 词典（慢）：%d\"%(words_fast.shape[0],words_slow.shape[0]))\n",
    "print(\"句典（快）：%d, 句典（慢）：%d\"%(sentence_fast.shape[0],sentence_slow.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bcebe550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删去部分pattern\n",
    "sentence_fast = sentence_fast.loc[~sentence_fast.key.isin([\"时间 短暂\",\"时光 短暂\",\"日子 短暂\"])].copy()\n",
    "def slow_exclude(x):\n",
    "    key = x.key\n",
    "    pattern = x.template\n",
    "    if pattern in [\"[prep][time]\",\"[hope][time][adj]\"]:\n",
    "        return True\n",
    "    if pattern == \"[time]感觉[adj]\" and \"长\" in key:\n",
    "        return True\n",
    "    if pattern == \"[time][adj]\" and \"岁月\" in key:\n",
    "        return True\n",
    "    if pattern == \"[time][still]\" and key.split(\" \")[-1] in [\"停止\",\"好长\",\"停了\"]:\n",
    "        return True\n",
    "    if pattern in [\"[time][prepadj]\",\"[time]过[prepadj]\"] and key[-1] in [\"长\",\"久\"]:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "sentence_slow[\"exclude\"] = sentence_slow.apply(lambda x: slow_exclude(x),axis=1)\n",
    "sentence_slow = sentence_slow.loc[sentence_slow.exclude==False].drop(columns = \"exclude\").copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d58f4e6b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "筛选后\n",
      "词典（快）：24238, 词典（慢）：1783\n",
      "句典（快）：27081, 句典（慢）：3394\n"
     ]
    }
   ],
   "source": [
    "# 2. 从2019.12.27开始 \n",
    "print(\"筛选后\")\n",
    "print(\"词典（快）：%d, 词典（慢）：%d\"%(words_fast.shape[0],words_slow.shape[0]))\n",
    "print(\"句典（快）：%d, 句典（慢）：%d\"%(sentence_fast.shape[0],sentence_slow.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7187eaeb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "筛选后\n",
      "词典（快）：24224, 词典（慢）：1772\n",
      "句典（快）：27080, 句典（慢）：3394\n"
     ]
    }
   ],
   "source": [
    "# 3. 从2020.1.20开始\n",
    "print(\"筛选后\")\n",
    "print(\"词典（快）：%d, 词典（慢）：%d\"%(words_fast.shape[0],words_slow.shape[0]))\n",
    "print(\"句典（快）：%d, 句典（慢）：%d\"%(sentence_fast.shape[0],sentence_slow.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54eabcd9",
   "metadata": {},
   "source": [
    "### 2. 合并词典快与句典快，删除完全相同的，并统计数目，慢同理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5431aefa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "快 词典与句典重合的数量：1828/51304\n",
      "慢 词典与句典重合的数量：23/5166\n"
     ]
    }
   ],
   "source": [
    "words_fast[\"source\"] = \"words\"\n",
    "words_slow[\"source\"] = \"words\"\n",
    "words_fast.rename(columns={\"key\":\"keyword\"},inplace=True)\n",
    "words_slow.rename(columns={\"key\":\"keyword\"},inplace=True)\n",
    "sentence_fast[\"source\"] = \"sentence\"\n",
    "sentence_slow[\"source\"] = \"sentence\"\n",
    "sentence_fast.rename(columns={\"key\":\"keypattern\"},inplace=True)\n",
    "sentence_slow.rename(columns={\"key\":\"keypattern\"},inplace=True)\n",
    "all_fast = words_fast.append(sentence_fast)\n",
    "all_slow = words_slow.append(sentence_slow)\n",
    "print(\"快 词典与句典重合的数量：%d/%d\"%(all_fast.shape[0]-all_fast._id.nunique(),all_fast.shape[0]))\n",
    "print(\"慢 词典与句典重合的数量：%d/%d\"%(all_slow.shape[0]-all_slow._id.nunique(),all_slow.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "54a7858f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "去重后：快有49476, 慢有5153\n"
     ]
    }
   ],
   "source": [
    "# 重合的weibo单独处理\n",
    "both_fast = sentence_fast.merge(words_fast[[\"_id\",\"keyword\"]],on=[\"_id\"],how=\"inner\")\n",
    "both_slow = sentence_slow.merge(words_slow[[\"_id\",\"keyword\"]],on=[\"_id\"],how=\"inner\")\n",
    "all_fast = both_fast.append(sentence_fast.loc[~sentence_fast._id.isin(both_fast._id.unique())]).append(\n",
    "                words_fast.loc[~words_fast._id.isin(both_fast._id.unique())])\n",
    "all_slow = both_slow.append(sentence_slow.loc[~sentence_slow._id.isin(both_slow._id.unique())]).append(\n",
    "                words_slow.loc[~words_slow._id.isin(both_slow._id.unique())])\n",
    "print(\"去重后：快有%d, 慢有%d\"%(all_fast.shape[0],all_slow.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5f4685fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"Final_dict/FebStart_0402/\",exist_ok=True)\n",
    "all_fast.to_csv(\"Final_dict/FebStart_0402/Fast.csv\",index=False)\n",
    "all_slow.to_csv(\"Final_dict/FebStart_0402/Slow.csv\",index=False)\n",
    "all_fast[[\"_id\",\"content\"]].to_csv(\"Final_dict/FebStart_0402/Fast_content.csv\",index=False,sep=\"\\t\")\n",
    "all_slow[[\"_id\",\"content\"]].to_csv(\"Final_dict/FebStart_0402/Slow_content.csv\",index=False,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d9c73c",
   "metadata": {},
   "source": [
    "### 3. 快&慢微博分别做去重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c084216",
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_weibos = all_fast[[\"_id\",\"content\"]].set_index(\"_id\").to_dict()['content']\n",
    "fast_weibo_ids = list(fast_weibos.keys())\n",
    "fast_weibos_set = {}\n",
    "for key in fast_weibo_ids:\n",
    "    fast_weibos_set[key] = set(fast_weibos[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ae529576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49476"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fast_weibo_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "661d78e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3face883864d4236ad2ac6ac263d7d91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "root_sim = np.arange(len(fast_weibo_ids)).astype(int)\n",
    "def find_root(leaf):\n",
    "    if leaf == root_sim[leaf]:\n",
    "        return leaf\n",
    "    return find_root(root_sim[leaf])\n",
    "\n",
    "def judge_similar(id1, id2, min_len=140, min_sim=0.9):\n",
    "    text1,text2 = fast_weibos[id1], fast_weibos[id2]\n",
    "    if len(text1)>min_len and len(text2)>min_len:\n",
    "        s1,s2 = fast_weibos_set[id1], fast_weibos_set[id2]\n",
    "        if len(s1&s2) / len(s1|s2) > min_sim:\n",
    "            return True\n",
    "        return False\n",
    "    return False\n",
    "\n",
    "MIN_LEN=50\n",
    "MIN_SIM=0.8\n",
    "cnt = 0\n",
    "for i,id1 in tqdm(enumerate(fast_weibo_ids)):\n",
    "    if len(fast_weibos[id1])<=MIN_LEN:\n",
    "        continue\n",
    "    if root_sim[i] != i:\n",
    "        continue # has been merged\n",
    "    for j,id2 in enumerate(fast_weibo_ids[i+1:]):\n",
    "        if judge_similar(id1,id2,min_len=MIN_LEN,min_sim=MIN_SIM):\n",
    "            root_sim[i+1+j] = find_root(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "31c0e5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_similar_dict = {}\n",
    "for fid in range(len(root_sim)):\n",
    "    if fid != root_sim[fid]:\n",
    "        fast_similar_dict[root_sim[fid]] = fast_similar_dict.get(root_sim[fid],[])\n",
    "        fast_similar_dict[root_sim[fid]].append(fid)\n",
    "fast_similar_id_list = []\n",
    "for key in fast_similar_dict:\n",
    "    fast_similar_id_list.append([fast_weibo_ids[key]]+[fast_weibo_ids[i] for i in fast_similar_dict[key]])\n",
    "\n",
    "all_similar = []\n",
    "for id_list in fast_similar_id_list:\n",
    "    all_similar += id_list\n",
    "all_fast_nosim = all_fast.loc[~all_fast._id.isin(all_similar)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "10da2a43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a562c42e35fe476abd6abb4b23a938b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.makedirs(\"Final_dict/0402/\",exist_ok=True)\n",
    "Datadir = \"Final_dict/0402/\"\n",
    "all_fast_nosim.to_csv(os.path.join(Datadir,\"Fast_无相似微博.csv\"),index=False)\n",
    "fast_same_person = pd.DataFrame()\n",
    "fast_diff_person = pd.DataFrame()\n",
    "for idx, id_list in tqdm(enumerate(fast_similar_id_list)):\n",
    "    partial = all_fast.loc[all_fast._id.isin(id_list)].copy()\n",
    "    partial[\"similar_id\"] = idx\n",
    "    partial[\"similar_grouplength\"] = min([len(fast_weibos[w_id]) for w_id in id_list])\n",
    "    if partial.user_id.nunique()>1:\n",
    "        fast_diff_person = fast_diff_person.append(partial)\n",
    "    else:\n",
    "        fast_same_person = fast_same_person.append(partial)\n",
    "fast_same_person.to_csv(os.path.join(Datadir,\"Fast_同user相似微博_L50.csv\"),index=False)\n",
    "fast_diff_person.to_csv(os.path.join(Datadir,\"Fast_异user相似微博_L50.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bb45882d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/lijiayu/anaconda3/envs/torch2/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(41327, 523, 7626)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_fast_nosim.drop_duplicates(subset=[\"_id\"],inplace=True)#,ignore_index=True)\n",
    "fast_same_person.drop_duplicates(subset=[\"_id\"],inplace=True)#,ignore_index=True)\n",
    "fast_diff_person.drop_duplicates(subset=[\"_id\"],inplace=True)#,ignore_index=True)\n",
    "all_fast_nosim.shape[0],fast_same_person.shape[0],fast_diff_person.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "487bd93d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/lijiayu/anaconda3/lib/python3.7/site-packages/xlsxwriter/worksheet.py:931: UserWarning: Ignoring URL 'http://t.cn/A6hyIUJv%20%20可怕的不是别人比你优秀，而是比你优秀的人比你还努力！（每日金句）%20我正在参加@莫若吻@文凤组织的“暖心-21天写作陪伴营”。2020，坚持每日写作Day1:《来，我们一起向上努力》%20期待你和我一起变得优秀！%20' with link or location/anchor > 255 characters since it exceeds Excel's limit for URLS\n",
      "  force_unicode(url))\n",
      "/work/lijiayu/anaconda3/lib/python3.7/site-packages/xlsxwriter/worksheet.py:931: UserWarning: Ignoring URL 'http://t.cn/A6hyInSr%20%20可怕的不是别人比你优秀，而是比你优秀的人比你还努力！（每日金句）%20我正在参加@莫若吻@文凤组织的“暖心-21天写作陪伴营”。2020，坚持每日写作Day1:《来，做我们一起向上努力》%20期待你和我一起变得优秀！%20' with link or location/anchor > 255 characters since it exceeds Excel's limit for URLS\n",
      "  force_unicode(url))\n"
     ]
    }
   ],
   "source": [
    "# # 整理成excel表格\n",
    "# f_writer = pd.ExcelWriter(os.path.join(Datadir,\"Fast_sample.xlsx\"))\n",
    "# all_fast_nosim.sample(frac=0.01,random_state=0).to_excel(f_writer,sheet_name=\"无重复-%d(0.01)\"%(all_fast_nosim.shape[0]),index=False)\n",
    "\n",
    "# # a = fast_same_person.loc[fast_same_person.similar_grouplength<50]\n",
    "# # a.to_excel(f_writer,sheet_name=\"同user-30到50字-%d组%d条\"%(a.similar_id.nunique(),a.shape[0]),index=False)\n",
    "# a = fast_same_person.loc[(fast_same_person.similar_grouplength<70)&(fast_same_person.similar_grouplength>=50)]\n",
    "# a.to_excel(f_writer,sheet_name=\"同user-50到70字-%d组%d条\"%(a.similar_id.nunique(),a.shape[0]),index=False)\n",
    "# a = fast_same_person.loc[(fast_same_person.similar_grouplength<20000)&(fast_same_person.similar_grouplength>=70)]\n",
    "# a.to_excel(f_writer,sheet_name=\"同user-多于70字-%d组%d条\"%(a.similar_id.nunique(),a.shape[0]),index=False)\n",
    "\n",
    "# np.random.seed(0)\n",
    "# # a = fast_diff_person.loc[fast_diff_person.similar_grouplength<50]\n",
    "# # sample_ids = np.random.choice(a.similar_id.unique(),size=100,replace=False)\n",
    "# # a.loc[a.similar_id.isin(sample_ids)].to_excel(f_writer,sheet_name=\"异user-30到50字-%d组%d条(100组)\"%(a.similar_id.nunique(),a.shape[0]),index=False)\n",
    "# a = fast_diff_person.loc[(fast_diff_person.similar_grouplength<70)&(fast_diff_person.similar_grouplength>=50)]\n",
    "# sample_ids = np.random.choice(a.similar_id.unique(),size=100,replace=False)\n",
    "# a.loc[a.similar_id.isin(sample_ids)].to_excel(f_writer,sheet_name=\"异user-50到70字-%d组%d条(100组)\"%(a.similar_id.nunique(),a.shape[0]),index=False)\n",
    "# a = fast_diff_person.loc[(fast_diff_person.similar_grouplength<20000)&(fast_diff_person.similar_grouplength>=70)]\n",
    "# sample_ids = np.random.choice(a.similar_id.unique(),size=100,replace=False)\n",
    "# a.loc[a.similar_id.isin(sample_ids)].to_excel(f_writer,sheet_name=\"异user-多于70字-%d组%d条(100组)\"%(a.similar_id.nunique(),a.shape[0]),index=False)\n",
    "\n",
    "# f_writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1d329c3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5143"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slow_weibos = all_slow[[\"_id\",\"content\"]].set_index(\"_id\").to_dict()['content']\n",
    "slow_weibo_ids = list(slow_weibos.keys())\n",
    "slow_weibos_set = {}\n",
    "for key in slow_weibo_ids:\n",
    "    slow_weibos_set[key] = set(slow_weibos[key])\n",
    "len(slow_weibo_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a25f64db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc1473d9203445e5b07d0907e3d9bab1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "root_sim = np.arange(len(slow_weibo_ids)).astype(int)\n",
    "def find_root(leaf):\n",
    "    if leaf == root_sim[leaf]:\n",
    "        return leaf\n",
    "    return find_root(root_sim[leaf])\n",
    "\n",
    "def judge_similar(id1, id2, min_len=140, min_sim=0.9):\n",
    "    text1,text2 = slow_weibos[id1], slow_weibos[id2]\n",
    "    if len(text1)>min_len and len(text2)>min_len:\n",
    "        s1,s2 = slow_weibos_set[id1], slow_weibos_set[id2]\n",
    "        if len(s1&s2) / len(s1|s2) > min_sim:\n",
    "            return True\n",
    "        return False\n",
    "    return False\n",
    "\n",
    "MIN_LEN=50\n",
    "MIN_SIM=0.8\n",
    "cnt = 0\n",
    "for i,id1 in tqdm(enumerate(slow_weibo_ids)):\n",
    "    if len(slow_weibos[id1])<=MIN_LEN:\n",
    "        continue\n",
    "    if root_sim[i] != i:\n",
    "        continue # has been merged\n",
    "    for j,id2 in enumerate(slow_weibo_ids[i+1:]):\n",
    "        if judge_similar(id1,id2,min_len=MIN_LEN,min_sim=MIN_SIM):\n",
    "            root_sim[i+1+j] = find_root(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2ae6c649",
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_similar_dict = {}\n",
    "for fid in range(len(root_sim)):\n",
    "    if fid != root_sim[fid]:\n",
    "        slow_similar_dict[root_sim[fid]] = slow_similar_dict.get(root_sim[fid],[])\n",
    "        slow_similar_dict[root_sim[fid]].append(fid)\n",
    "slow_similar_id_list = []\n",
    "for key in slow_similar_dict:\n",
    "    slow_similar_id_list.append([slow_weibo_ids[key]]+[slow_weibo_ids[i] for i in slow_similar_dict[key]])\n",
    "\n",
    "all_similar = []\n",
    "for id_list in slow_similar_id_list:\n",
    "    all_similar += id_list\n",
    "all_slow_nosim = all_slow.loc[~all_slow._id.isin(all_similar)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "61ec48b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bca67b9e403470eb21c1736f30e058e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_slow_nosim.to_csv(os.path.join(Datadir,\"slow_无相似微博.csv\"),index=False)\n",
    "slow_same_person = pd.DataFrame()\n",
    "slow_diff_person = pd.DataFrame()\n",
    "for idx, id_list in tqdm(enumerate(slow_similar_id_list)):\n",
    "    partial = all_slow.loc[all_slow._id.isin(id_list)].copy()\n",
    "    partial[\"similar_id\"] = idx\n",
    "    partial[\"similar_grouplength\"] = min([len(slow_weibos[w_id]) for w_id in id_list])\n",
    "    if partial.user_id.nunique()>1:\n",
    "        slow_diff_person = slow_diff_person.append(partial)\n",
    "    else:\n",
    "        slow_same_person = slow_same_person.append(partial)\n",
    "slow_same_person.to_csv(os.path.join(Datadir,\"slow_同user相似微博_L50.csv\"),index=False)\n",
    "slow_diff_person.to_csv(os.path.join(Datadir,\"slow_异user相似微博_L50.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "63ff7be8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4459, 43, 651)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_slow_nosim.shape[0],slow_same_person.shape[0],slow_diff_person.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c81959b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41327, 523, 7626)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_fast_nosim.shape[0],fast_same_person.shape[0],fast_diff_person.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "215ff127",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(482, 17)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slow_diff_person.loc[slow_diff_person.similar_grouplength>70].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d0fcda7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 整理成excel表格\n",
    "# s_writer = pd.ExcelWriter(os.path.join(Datadir,\"Slow_sample.xlsx\"))\n",
    "# all_slow_nosim.sample(frac=0.1,random_state=0).to_excel(s_writer,sheet_name=\"无重复-%d(0.1)\"%(all_slow_nosim.shape[0]),index=False)\n",
    "\n",
    "# # a = slow_same_person.loc[slow_same_person.similar_grouplength<50]\n",
    "# # a.to_excel(s_writer,sheet_name=\"同user-30到50字-%d组%d条\"%(a.similar_id.nunique(),a.shape[0]),index=False)\n",
    "# a = slow_same_person.loc[(slow_same_person.similar_grouplength<70)&(slow_same_person.similar_grouplength>=50)]\n",
    "# a.to_excel(s_writer,sheet_name=\"同user-50到70字-%d组%d条\"%(a.similar_id.nunique(),a.shape[0]),index=False)\n",
    "# a = slow_same_person.loc[(slow_same_person.similar_grouplength<20000)&(slow_same_person.similar_grouplength>=70)]\n",
    "# a.to_excel(s_writer,sheet_name=\"同user-多于70字-%d组%d条\"%(a.similar_id.nunique(),a.shape[0]),index=False)\n",
    "\n",
    "# np.random.seed(0)\n",
    "# # a = slow_diff_person.loc[slow_diff_person.similar_grouplength<50]\n",
    "# # if a.similar_id.nunique()>100:\n",
    "# #     sample_ids = np.random.choice(a.similar_id.unique(),size=100,replace=False)\n",
    "# # else:\n",
    "# #     sample_ids = a.similar_id.unique()\n",
    "# # a.loc[a.similar_id.isin(sample_ids)].to_excel(s_writer,sheet_name=\"异user-30到50字-%d组%d条(100组)\"%(a.similar_id.nunique(),a.shape[0]),index=False)\n",
    "# a = slow_diff_person.loc[(slow_diff_person.similar_grouplength<70)&(slow_diff_person.similar_grouplength>=50)]\n",
    "# if a.similar_id.nunique()>100:\n",
    "#     sample_ids = np.random.choice(a.similar_id.unique(),size=100,replace=False)\n",
    "# else:\n",
    "#     sample_ids = a.similar_id.unique()\n",
    "# a.loc[a.similar_id.isin(sample_ids)].to_excel(s_writer,sheet_name=\"异user-50到70字-%d组%d条(100组)\"%(a.similar_id.nunique(),a.shape[0]),index=False)\n",
    "# a = slow_diff_person.loc[(slow_diff_person.similar_grouplength<20000)&(slow_diff_person.similar_grouplength>=70)]\n",
    "# if a.similar_id.nunique()>100:\n",
    "#     sample_ids = np.random.choice(a.similar_id.unique(),size=100,replace=False)\n",
    "# else:\n",
    "#     sample_ids = a.similar_id.unique()\n",
    "# a.loc[a.similar_id.isin(sample_ids)].to_excel(s_writer,sheet_name=\"异user-多于70字-%d组%d条(100组)\"%(a.similar_id.nunique(),a.shape[0]),index=False)\n",
    "\n",
    "# s_writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "32a4aec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Different person remain: 0, Same person remain: 0\n",
      "Final 41327\n",
      "Different person remain: 0, Same person remain: 0\n",
      "Final 4459\n"
     ]
    }
   ],
   "source": [
    "# 确定以50字为threshold，筛去多次重复的\n",
    "\n",
    "# 1. diff person：筛去50字以上的即可\n",
    "# 2. same person: 保留50字以下的一条\n",
    "\n",
    "fast_diff_remain = fast_diff_person.loc[fast_diff_person.similar_grouplength<50].drop(\n",
    "                        columns = [\"similar_id\",\"similar_grouplength\"])\n",
    "fast_same_remain = fast_same_person.loc[fast_same_person.similar_grouplength<50].groupby([\"similar_id\"]).head(1).drop(\n",
    "                        columns = [\"similar_id\",\"similar_grouplength\"])\n",
    "print(\"Different person remain: %d, Same person remain: %d\"%(fast_diff_remain.shape[0],fast_same_remain.shape[0]))\n",
    "all_fast_final = all_fast_nosim.append(fast_same_remain).append(fast_diff_remain)\n",
    "print(\"Final %d\"%(all_fast_final.shape[0]))\n",
    "\n",
    "slow_diff_remain = slow_diff_person.loc[slow_diff_person.similar_grouplength<50].drop(\n",
    "                        columns = [\"similar_id\",\"similar_grouplength\"])\n",
    "slow_same_remain = slow_same_person.loc[slow_same_person.similar_grouplength<50].groupby([\"similar_id\"]).head(1).drop(\n",
    "                        columns = [\"similar_id\",\"similar_grouplength\"])\n",
    "print(\"Different person remain: %d, Same person remain: %d\"%(slow_diff_remain.shape[0],slow_same_remain.shape[0]))\n",
    "all_slow_final = all_slow_nosim.append(slow_same_remain).append(slow_diff_remain)\n",
    "print(\"Final %d\"%(all_slow_final.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068ce9eb",
   "metadata": {},
   "source": [
    "### 4. 快与慢都出现的，去重，作为单独的dataset，both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "25c9996b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both: 604\n"
     ]
    }
   ],
   "source": [
    "fast_ids = set(all_fast_final._id.unique())\n",
    "slow_ids = set(all_slow_final._id.unique())\n",
    "both_ids = fast_ids&slow_ids\n",
    "print(\"Both: %d\"%(len(both_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d3db8d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast: 40723, Slow: 3852, Both: 607\n"
     ]
    }
   ],
   "source": [
    "both = all_fast_final.loc[all_fast_final._id.isin(both_ids)].merge(all_slow_final[\n",
    "                    [\"_id\",\"template_id\",\"template\",\"keypattern\",\"source\",\"keyword\"]],on=\"_id\",how=\"left\")\n",
    "fast_final = all_fast_final.loc[~all_fast_final._id.isin(both_ids)].copy()\n",
    "slow_final = all_slow_final.loc[~all_slow_final._id.isin(both_ids)].copy()\n",
    "\n",
    "print(\"Fast: %d, Slow: %d, Both: %d\"%(fast_final.shape[0],slow_final.shape[0],both.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f2a99d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_final = fast_final.reset_index(drop=True)\n",
    "slow_final = slow_final.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a91d6204",
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_final[\"timestamp\"] = fast_final[\"created_at\"].apply(lambda x: \n",
    "            datetime.strptime(x,\"%Y-%m-%d %H:%M\") if len(x.split(\":\"))==2 else datetime.strptime(x,\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d8ea1f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_final[\"timestamp\"] = slow_final[\"created_at\"].apply(lambda x: \n",
    "            datetime.strptime(x,\"%Y-%m-%d %H:%M\") if len(x.split(\":\"))==2 else datetime.strptime(x,\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "30f15129",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2019, 12, 27, 0, 0)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime(2019,12,27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4988d02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_valid = fast_final.loc[fast_final.timestamp>=datetime(2020,1,20)].copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "88d15877",
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_valid = slow_final.loc[slow_final.timestamp>=datetime(2020,1,20)].copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "312c4e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "both.to_csv(os.path.join(Datadir,\"Both_final.csv\"),index=False)\n",
    "fast_valid.to_csv(os.path.join(Datadir,\"Fast_final.csv\"),index=False)\n",
    "slow_valid.to_csv(os.path.join(Datadir,\"Slow_final.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a43fdf4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40732, 20), (3852, 20), (607, 20))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_valid.shape,slow_valid.shape,both.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7d5021c1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40723, 16), (3852, 16), (607, 20))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_valid.shape,slow_valid.shape,both.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c5e4fd",
   "metadata": {},
   "source": [
    "-----\n",
    "## Final dataset基本信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bba1ad77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/lijiayu/anaconda3/envs/torch2/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (1,2) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "Datadir = \"Final_dict/0402/\"\n",
    "fast_valid = pd.read_csv(os.path.join(Datadir,\"Fast_final.csv\"))\n",
    "slow_valid = pd.read_csv(os.path.join(Datadir,\"Slow_final.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b717e30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40723, 16), (3852, 16))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_valid.shape,slow_valid.shape#,both.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7611e88b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3845"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slow_valid['_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bb6f7ea",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence    24328\n",
       "words       16395\n",
       "Name: source, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[time]过[de]快         13578\n",
       "[time][fast]          5167\n",
       "[time][pass]          3365\n",
       "[words]               1514\n",
       "[hope][time][adj]      373\n",
       "[adv][n]               234\n",
       "[adv]过了[time]           97\n",
       "Name: template, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "转眼      11214\n",
       "转瞬即逝     1107\n",
       "时光飞逝      762\n",
       "时光荏苒      530\n",
       "时光匆匆      468\n",
       "白驹过隙      379\n",
       "时间飞逝      302\n",
       "荏苒        241\n",
       "似水流年      190\n",
       "岁月如梭      172\n",
       "Name: keyword, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fast_valid.reset_index(drop=True,inplace=True)\n",
    "slow_valid.reset_index(drop=True,inplace=True)\n",
    "# 1. 来源\n",
    "display(fast_valid.source.value_counts()) # 来自句典or词典\n",
    "display(fast_valid.loc[fast_valid.source==\"sentence\",\"template\"].value_counts()) # 句典pattern分布\n",
    "display(fast_valid.loc[fast_valid.source==\"words\",\"keyword\"].value_counts().head(10)) # 词典的keyword分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "62214fdd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence    2598\n",
       "words       1254\n",
       "Name: source, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[feel][past][long]    941\n",
       "[time][still]         539\n",
       "[time]过[de]慢          489\n",
       "[time][adj]           430\n",
       "[time][prepadj]       129\n",
       "[time]感觉[adj]          64\n",
       "[time]过[prepadj]        6\n",
       "Name: template, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "度日如年    1243\n",
       "一日三秋       5\n",
       "寸阴若岁       5\n",
       "日长似岁       1\n",
       "Name: keyword, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. 来源\n",
    "display(slow_valid.source.value_counts()) # 来自句典or词典\n",
    "display(slow_valid.loc[slow_valid.source==\"sentence\",\"template\"].value_counts()) # 句典pattern分布\n",
    "display(slow_valid.loc[slow_valid.source==\"words\",\"keyword\"].value_counts().head(10)) # 词典的keyword分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6dbfebc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence    505\n",
       "words       102\n",
       "Name: source_x, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(both.source_x.value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
